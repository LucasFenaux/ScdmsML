{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ac7lXyk6yLV"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook will present how to run the code that's in the ScdmsML github repository. https://github.com/LucasFenaux/ScdmsML \n",
        "\n",
        "The general structure is the following. The code in the github is divided in multiple experiments, which are meant to train different models on different types of datasets. Each experiment follows roughly the following structure:\n",
        "\n",
        "*   Pre-Processing\n",
        "*   Dataloading\n",
        "*   Model\n",
        "*   Train, Run and Test code\n",
        "\n",
        "And I'll close off with a Conclusion\n",
        "\n",
        "While the Model, Train, Run and Test code is shared most of the time, the Pre-processing and Dataloading is mostly experiment specific.\n",
        "\n",
        "In this notebook, I will detail and setup the code to run the experiment that can be found in the \"run_raw_all_channels.py\" file. This notebook can be adapted to run any of the experiments by just substituting the appropriate code where they differ.\n",
        "\n",
        "\n",
        "For most of our experiments, we used photoneutron data from the Soudan DMC_V1-5 production and therefore this notebook will be tailored towards this particular dataset.\n",
        "\n",
        "**I would not recommend actually trying to run this notebook locally or using Google Colab as it can be quite demanding both in memory/gpu memory consumption as well as processing power and file storage. This notebook should be used as a tutorial/helper to build/extract the parts of the code you need to either re-run our experiments or run your own new experiments**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CubjtOcR8Qf8"
      },
      "source": [
        "# Pre-Processing\n",
        "\n",
        "The pre-processing can be split up into two parts, that only need to be ran once each to produce the desired files that can then be used for dataloading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kCxphms8Pq_"
      },
      "source": [
        "def pre_processing_part_1():\n",
        "  \"\"\"Preprocessing for the raw data files\n",
        "  Gathers the data from all the different files into a singular matrix, then\n",
        "  removes all the meta data except the event number and event channel before \n",
        "  saving it to a numpy file\"\"\"\n",
        "    # First file is data dump, DO NOT INCLUDE IT\n",
        "    filepaths = []\n",
        "    for i in range(2, 977):\n",
        "        last_part = \"\"\n",
        "        if i >= 100:\n",
        "            last_part += str(i)\n",
        "        elif i >= 10:\n",
        "            last_part = last_part + \"0\" + str(i)\n",
        "        else:\n",
        "            last_part = last_part + \"00\" + str(i)\n",
        "        last_part += \".gz\"\n",
        "        filepaths.append(\n",
        "            \"path/to/data/folder/libinput_sb-70V_F0\" + last_part)   # this was the name of the files in this particular production, could change\n",
        "\n",
        "    logging.info(\"getting all events\")\n",
        "    matrix = get_all_events(filepaths)\n",
        "    logging.info(\"done getting events\")\n",
        "    logging.info(\"size of the data matrix {}\".format(sys.getsizeof(matrix)))\n",
        "    # we only care about event number and channel\n",
        "    logging.info(\"matrix shape before column deletion {}\".format(np.shape(matrix)))\n",
        "    matrix = np.delete(matrix, [1, 2, 4], axis=1)\n",
        "    logging.info(\"matrix shape after deletion {}\".format(np.shape(matrix)))\n",
        "    np.save(\"path/to/save/folder/pre_processed_data.npy\", matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAEEguLP95ZS"
      },
      "source": [
        "After running the first part, we'll then run the second part that will format the data in the correct way for us to use.\n",
        "Notice that we have a function to check the format of the given data, if this check fails, I would recommend either writing your own code to get the data in the file pre-processed above in the format wanted by the function or to run the deprecated version of this pre-processing that can be found in the 'run_raw_all_channels.py' file of the github. \n",
        "\n",
        "The reason for this format check is that until now, the production files were always in this format and it speeds up the pre-processing process significantly to assume that they are, the deprecated code still works, however, it makes minimal assumptions on the layout of the events in the data matrix and therefore can take quite a long time to run if the amount of data is substantial ($\\geq$ 10000 events) \n",
        "\n",
        "Also, this pre-processing assumes that we are only using 8 channels, however if it's not the case, it can be easily modified to adapt to any specific number of channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoNAemIO9zJt"
      },
      "source": [
        "def check_format(data):\n",
        "    \"\"\" Function to check the format of the pre-processed data after the first round of pre-processing\n",
        "    and verify that it is in the format where we have for each event number, all 8 channel outputs in a row in the same\n",
        "    order across all events\"\"\"\n",
        "    n = np.shape(data)[0]\n",
        "    all_event_numbers = data[:, 0]\n",
        "    all_channel_numbers = data[:, 1]\n",
        "    channels = []\n",
        "    first_event = None\n",
        "    current_event = None\n",
        "    shape_matches = False\n",
        "    for i in range(n):\n",
        "        if first_event is None:\n",
        "            first_event = all_event_numbers[i]\n",
        "            current_event = first_event\n",
        "        if current_event != all_event_numbers[i] and i % len(channels) != 0:\n",
        "            logging.ERROR(\"data is not in the correct format, event numbers are not order properly, aborting\")\n",
        "            print(\"data is not in the correct format, event numbers are not order properly, aborting\")\n",
        "            return False, channels, all_channel_numbers[i], i % 8\n",
        "        if first_event == current_event:\n",
        "            channels.append(all_channel_numbers[i])\n",
        "        elif not shape_matches:\n",
        "            if i % len(channels) != 0:\n",
        "                logging.ERROR(\"data is missing some rows\")\n",
        "                print(\"data is missing some rows\")\n",
        "                return False, [], 0, 0\n",
        "            else:\n",
        "                shape_matches = True\n",
        "        if channels[i%8] != all_channel_numbers[i]:\n",
        "            logging.ERROR(\"data is not in the correct format, channel numbers are not order properly, aborting\")\n",
        "            print(\"data is not in the correct format, channel numbers are not order properly, aborting\")\n",
        "            return False, channels, all_channel_numbers[i], i % 8\n",
        "\n",
        "    # if we get here, it means the data is in the correct format\n",
        "    return True, channels, -1, -1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM4IKqD9_W7O"
      },
      "source": [
        "What this pre-processing part does is that it takes in the event matrix that has the following layout (assumed after using the check format function) for a row:\n",
        "\n",
        "[event_number|channel_number|timestep 0|timestep 1|....|timestep 4094|timestep 4095]\n",
        "\n",
        "and the column layout is the following:\n",
        "\n",
        "[[first event_number|first selected channel|...]\n",
        "\n",
        "[first event_number|second selected channel]\n",
        "\n",
        "...\n",
        "\n",
        "[last even_number| eighth selected channel]]\n",
        "\n",
        "and turns it into a 3D matrix where each 2D submatrix contains all the 8 channels of each event number together. The final matrix has the following shape: **number of events x length of the sequence (usually 4096) x number of channels (usually 8)**\n",
        "\n",
        "The code also stores the ordering of the event numbers in a seperate file to figure out the labels during the dataloading part.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_XDkDou-_zV"
      },
      "source": [
        "def multi_process_pre_procesing_part_2():\n",
        "    \"\"\" Supposed to do the same thing as the slow pre processing part2, however checks for the format first\n",
        "    in order to speed up the process. Does require the proper format however\n",
        "    \"\"\"\n",
        "    # First check the format\n",
        "    print(\"start loading\")\n",
        "    data = np.load(\"path/to/save/folder/pre_processed_data.npy\")\n",
        "    print(\"loaded intial pre-processed data\")\n",
        "    is_valid, channel_order, a, b = check_format(data)\n",
        "    if not is_valid:\n",
        "        print(str(channel_order), str(a), str(b))\n",
        "        return\n",
        "\n",
        "    def multi_process_pre(submatrix_indices):\n",
        "        submatrix = data[submatrix_indices[0]:submatrix_indices[1], :]\n",
        "        all_event_numbers = submatrix[:, 0]\n",
        "        submatrix = np.delete(submatrix, 0, axis=1)  # remove ev\n",
        "        submatrix = np.delete(submatrix, 0, axis=1)  # remove channel num\n",
        "        n = int(np.shape(submatrix)[0]/8) # we shouldn't get any rounding error as the check format checks if we have the correct shape\n",
        "        submatrix_3D = []\n",
        "        event_numbers = []\n",
        "        for i in range(n):\n",
        "            a = submatrix[i:i+8, :]\n",
        "            a = np.transpose(a)\n",
        "            submatrix_3D.append(a)\n",
        "            event_numbers.append(all_event_numbers[8*i])\n",
        "        submatrix_3D = np.array(submatrix_3D)\n",
        "        assert np.shape(submatrix_3D)[0] == len(event_numbers)\n",
        "        return submatrix_3D, event_numbers\n",
        "\n",
        "    class Worker(Thread):\n",
        "        def __init__(self, input_queue, output_queue):\n",
        "            Thread.__init__(self)\n",
        "            self.input_queue = input_queue\n",
        "            self.output_queue = output_queue\n",
        "\n",
        "        def run(self):\n",
        "            while True:\n",
        "                indices = self.input_queue.get()\n",
        "                try:\n",
        "                    out_submatrix_3D, out_event_numbers = multi_process_pre(indices)\n",
        "                    self.output_queue.put((out_submatrix_3D, out_event_numbers))\n",
        "                finally:\n",
        "                    self.input_queue.task_done()\n",
        "\n",
        "    in_queue = Queue()\n",
        "    out_queue = Queue()\n",
        "    m = mp.cpu_count()\n",
        "    for x in range(m):\n",
        "        worker = Worker(in_queue, out_queue)\n",
        "        worker.daemon = True\n",
        "        worker.start()\n",
        "    rows = np.shape(data)[0]\n",
        "    chunk_size = int(rows/m)\n",
        "    while chunk_size%8 != 0:\n",
        "        chunk_size -= 1  # so that we cut on the event separation line and not before\n",
        "    for y in range(m):\n",
        "        # create the indices\n",
        "        if y == m - 1:\n",
        "            in_queue.put((y*chunk_size, rows))\n",
        "        else:\n",
        "            in_queue.put((y*chunk_size, (y+1)*chunk_size))\n",
        "\n",
        "    # Now we pick up the finished work and reconstruct the array\n",
        "    data_3D = None\n",
        "    events = None\n",
        "    for z in range(m):\n",
        "        sub_3D, evs = out_queue.get()\n",
        "        if data_3D is None and events is None:\n",
        "            data_3D = sub_3D\n",
        "            events = evs\n",
        "        else:\n",
        "            data_3D = np.concatenate((data_3D, sub_3D), axis=0)\n",
        "            events.extend(evs)\n",
        "        out_queue.task_done()\n",
        "    events = np.array(events)\n",
        "    np.save(\"path/to/save/folder/pre_processed_data_3D_all_attribute.npy\", data_3D)\n",
        "    np.save(\"path/to/save/folder/pre_processed_data_events_all_attributes.npy\", events)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-PL0uSpYHVJ"
      },
      "source": [
        "Finally, we normalize the resulting matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9y_g58fYLpu"
      },
      "source": [
        "def normalizing():\n",
        "    \"\"\" Normalizes the pre-processed data \"\"\"\n",
        "    data = np.load(\"path/to/save/folder/pre_processed_data_3D_all_attribute.npy\")\n",
        "    # this pre-processed data does not contain channel or event number anymore\n",
        "    normalizer = NDMinMaxScaler()\n",
        "    normalizer.fit(data)\n",
        "    print(np.shape(data))\n",
        "    normalized_data = normalizer.transform(data)\n",
        "    print(np.shape(normalized_data))\n",
        "\n",
        "    np.save(\"path/to/save/folder/pre_processed_normalized_data_3D_all_attribute.npy\", normalized_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sqsm8szCEjI"
      },
      "source": [
        "# This cell shows how the pre-processing should usually be run.\n",
        "pre_processing_part_1()\n",
        "multi_process_pre_procesing_part_2()\n",
        "normalizing()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKgHEu1XCAVp"
      },
      "source": [
        "# Dataloading\n",
        "\n",
        "Now that we're done with the pre-processing part, we can move on to the dataloading part. If you are unfamiliar with dataloading in Pytorch, I recommend you check out https://pytorch.org/docs/stable/data.html .\n",
        "\n",
        "The dataloading consists of two main parts. Fetching the labels from the data matrix and then assembling the Dataloader objects.\n",
        "In order to do this, we use a function called get_num_scatters which given the .mat init file for the experiment returns the scatters, which allows us to construct our ground truth values for the experiment (in our particular case, if it was a single or multiple scatter). This function can be found in the dataloading.py script in our github if you're interested in the specifics or adding it to your own code base.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVUKhLKfYfy8"
      },
      "source": [
        "# so we first fetch the scatters\n",
        "def all_channels_raw_data_loader(data_file, event_file, init_path, num_scatter_save_path, det=14):\n",
        "    all_data = np.load(data_file)\n",
        "    scatters, single_scatter = get_num_scatters(init_path, save_path=num_scatter_save_path, det=det)\n",
        "    evs = list(single_scatter.keys())\n",
        "    targets = []\n",
        "    all_event_numbers = np.load(event_file)\n",
        "    target_event_numbers = []\n",
        "    logging.info(\"data matrix shape {}\".format(np.shape(all_data)))\n",
        "    assert np.shape(all_data)[1] == 4096\n",
        "\n",
        "    for i in range(np.shape(all_data)[0]):\n",
        "        ev = all_event_numbers[i]\n",
        "        if ev not in evs:\n",
        "            logging.info(\"event number {} was not present in the init file and got deleted\".format(ev))\n",
        "            continue\n",
        "        target_event_numbers.append(ev)\n",
        "        targets.append(single_scatter[ev])\n",
        "\n",
        "    if len(np.unique(all_event_numbers)) - len(np.unique(target_event_numbers)) > 0:\n",
        "        logging.info(\"{} raw data events were not found in the init file\".format(len(all_event_numbers) - len(target_event_numbers)))\n",
        "    else:\n",
        "        logging.info(\"all raw data events were found in the init file\")\n",
        "\n",
        "    return all_data, targets, target_event_numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuZpBIruDYlT"
      },
      "source": [
        "# and then we assemble the DataLoader objects\n",
        "def torch_all_channels_raw_data_loader(batch_size=256,num_workers=1, pin_memory=False):\n",
        "    num_scatter_save_path = os.path.join(\"../results/files/pca_numscatters.txt\")\n",
        "    data, targets, target_evs = all_channels_raw_data_loader(\n",
        "        \"path/to/save/folder/pre_processed_normalized_data_3D_all_attribute.npy.npy\",\n",
        "        \"path/to/save/folder/pre_processed_data_events_all_attributes.npy\",\n",
        "        \"path/to/save/folder/PhotoNeutronDMC_InitialTest10K_jswfix.mat\",  # the .mat init file\n",
        "        num_scatter_save_path)\n",
        "    print(np.min(data), np.max(data))\n",
        "    train_data, test_data, train_targets, test_targets = train_test_split(data,\n",
        "                                                                          targets)  # can add target_evs in there if you want to keep track of them as well\n",
        "\n",
        "    print(\"train data shape {}\".format(np.shape(train_data)))\n",
        "    print(\"test data shape {}\".format(np.shape(test_data)))\n",
        "    train_data = torch.Tensor(train_data)\n",
        "    train_targets = torch.Tensor(train_targets).to(torch.int64)\n",
        "    train_targets = torch.nn.functional.one_hot(train_targets).to(torch.float)\n",
        "    # assert torch.max(train_targets) <=1 and torch.min(train_targets) >= 0\n",
        "    test_data = torch.Tensor(test_data)\n",
        "    test_targets = torch.Tensor(test_targets).to(torch.int64)\n",
        "    # assert torch.max(test_targets) <=1 and torch.min(test_targets) >=0\n",
        "    test_targets = torch.nn.functional.one_hot(test_targets).to(torch.float)\n",
        "\n",
        "    # logging.info(\"{}, {}\".format(type(train_targets), type(test_targets)))\n",
        "    train_dataset = TensorDataset(train_data, train_targets)\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size, num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "    test_dataset = TensorDataset(test_data, test_targets)\n",
        "    test_sampler = SequentialSampler(test_dataset)\n",
        "    test_loader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size, num_workers=num_workers,\n",
        "                             pin_memory=pin_memory)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfeorS_pbhz1"
      },
      "source": [
        "This sorts out the dataloading. There are a couple of global variable that aren't explicitely set as to not clutter the notebook, if you're wondering how to set them, it is either talked about in the pytorch link a couple cells above or you can check out the details in the github repo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GchSHOkVcUcS"
      },
      "source": [
        "# Model\n",
        "\n",
        "In this section, I will describe a couple of models we used, their strong points and short comings as well as what could be expanded upon.\n",
        "\n",
        "I will also give a brief explanation of how those model are coded, if you want a more general explanation of how to code models in pytorch, you should checkout  https://pytorch.org/docs/stable/notes/extending.html . It explains their autograd system as well as how each part of the model is coded/works.\n",
        "\n",
        "In a general sense, when you construct a pytorch model, you need 2 methods. The __init__ and the forward methods. The forward method is what is called when you want to feed data into your model. It usually takes the component initialized in the __init__ method to perform operations on the given data that will then be used during backpropagation automatically with autograd."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0wUfOZLHbNO"
      },
      "source": [
        "## LSTM\n",
        "So first we have a regular lstm. This works by first passing the input sequence into the LSTMcell, then passing the last hidden state into a feedforward network (here 2 Linear Layers) to produce a prediction.\n",
        "The upside of this model is that it's simple and works well for short sequences. However in our case, since the sequences in this production are 4096 timesteps long, the LSTM really struggles and performs poorly.\n",
        "\n",
        "\n",
        "You can also find in the github a Bidirectional LSTM, it works as 3 LSTM cells, 1 processing the sequence forward, another one processing it backwards and a last one processing the output of the first two together and then feeding that into a FeedForward structure (2 Linear Layers here). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGVQAtZCcPKV"
      },
      "source": [
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Version V1.3\n",
        "    A regular one layer LSTM classifier using LSTMCell -> FFNetwork structure\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, label_size, device=torch.device(\"cuda\"), dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTMCell(input_dim, hidden_dim)\n",
        "        self.hidden2ff = nn.Linear(hidden_dim,  int(np.sqrt(hidden_dim)))\n",
        "        self.ff2label = nn.Linear(int(np.sqrt(hidden_dim)), label_size)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.device = device\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "        for name, param in self.hidden2ff.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "        for name, param in self.ff2label.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "        cs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "\n",
        "        for i in range(x.size()[1]):\n",
        "            hs, cs = self.lstm(x[:, i], (hs, cs))\n",
        "\n",
        "        hs = self.dropout(hs)\n",
        "        hs = self.hidden2ff(hs)\n",
        "        return self.sigmoid(self.ff2label(hs)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZwVf42zWLdK"
      },
      "source": [
        "## CNN_LSTM\n",
        "\n",
        "To improve performance, we then opted to improve our LSTM by adding a Convolutional Net to first perform feature extraction on the input before feeding it into the LSTM. This process has benefits that are two fold. First, it helps reduce the length the sequence from 4096 to the order of 100 timesteps, which is much more manageable for the LSTM. On top of that, it takes the 8 channels (features) we have, filters out noise and useless information for the current task as well as extract important features and information from the sequence. \n",
        "\n",
        "For this model, I'm presenting here the latest version of it tested, it does not however mean it is the version that performs the best. The problem we encountered with the first version of the model is that it requires a significantly bigger amount of data to train (we had roughly 40 000 samples, it probably needs at least an order of magnitude more than that) and therefore it was overfitting greatly. To reduce the overfitting, we added extra dropout layers as well as reduced the size of the Convolutional Net to reduce the complexity of the model. However, it still didn't perform well enough **so it would be worth revisiting both versions when aditionnal data has been acquired**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckgNChXBYaC-"
      },
      "source": [
        "class CNN_LSTM_Classifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Version V0.3\n",
        "    CNN+LSTM classifier using ConvNet -> LSTMCell -> FFNetwork structure\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, label_size, device=torch.device(\"cuda\"), dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.convnet1 = nn.Sequential(nn.Conv1d(in_channels=input_dim, out_channels=input_dim, kernel_size=7,\n",
        "                                               padding=2), nn.MaxPool1d(kernel_size=4),\n",
        "                                     nn.BatchNorm1d(input_dim), nn.ReLU()) # here to reduce noice\n",
        "        self.convnet2 = nn.Sequential(nn.Conv1d(in_channels=input_dim, out_channels=2*input_dim, kernel_size=5,\n",
        "                                               padding=2), nn.MaxPool1d(kernel_size=4),\n",
        "                                     nn.BatchNorm1d(2*input_dim), nn.ReLU())  # start extracting features and reduce size\n",
        "                                                                              # ro reduce complexity for lstm\n",
        "        self.convnet3 = nn.Sequential(nn.Conv1d(in_channels=2*input_dim, out_channels=4*input_dim, kernel_size=3,\n",
        "                                               padding=2), nn.MaxPool1d(kernel_size=2),\n",
        "                                     nn.BatchNorm1d(4*input_dim), nn.ReLU())\n",
        "        # removed to reduce model complexity to try and limit overfitting\n",
        "        # self.convnet4 = nn.Sequential(nn.Conv1d(in_channels=4*input_dim, out_channels=8*input_dim, kernel_size=4,\n",
        "        #                                        padding=2), nn.BatchNorm1d(8*input_dim), nn.ReLU())\n",
        "        # self.convnet5 = nn.Conv1d(in_channels=8*input_dim, out_channels=16*input_dim, kernel_size=4, padding=2)\n",
        "        # self.lstm = nn.LSTMCell(16*input_dim, hidden_dim)\n",
        "        self.convnet5 = nn.Conv1d(in_channels=4*input_dim, out_channels=4*input_dim, kernel_size=4, padding=2)\n",
        "        self.lstm = nn.LSTMCell(4*input_dim, hidden_dim)\n",
        "        self.hiddentoff = nn.Linear(hidden_dim, int(np.sqrt(hidden_dim)))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fftolabel = nn.Linear(int(np.sqrt(hidden_dim)), label_size)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.device = device\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "        for name, param in self.hiddentoff.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "        for name, param in self.fftolabel.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
        "        x = self.convnet1(x)\n",
        "        x = self.convnet2(x)\n",
        "        x = self.convnet3(x)\n",
        "        # x = self.convnet4(x)\n",
        "        x = self.convnet5(x)\n",
        "        x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
        "        x = self.dropout(x)\n",
        "        hs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "        cs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "\n",
        "        for i in range(x.size()[1]):\n",
        "            hs, cs = self.lstm(x[:, i], (hs, cs))\n",
        "            # hs = self.dropout(hs)\n",
        "            # cs = self.dropout(cs)\n",
        "\n",
        "        hs = self.dropout(hs)\n",
        "        hs = self.hiddentoff(hs)\n",
        "        hs = self.relu(hs)\n",
        "        # return self.sigmoid(self.hidden2label(hs.reshape(x.shape[0], -1)))\n",
        "        return self.sigmoid(self.fftolabel(hs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRk-Mbs4Yc3G"
      },
      "source": [
        "And here is the original more complex version V0.1 (V0.2 was misslabeled as 0.1 for a commit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQuJlIXIYhOK"
      },
      "source": [
        "\n",
        "class CNN_LSTM_Classifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Version V0.1\n",
        "    CNN+LSTM classifier using ConvNet -> LSTMCell -> FFNetwork structure\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, label_size, device=torch.device(\"cuda\"), dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.convnet1 = nn.Sequential(nn.Conv1d(in_channels=input_dim, out_channels=input_dim, kernel_size=4,\n",
        "                                               padding=2), nn.MaxPool1d(kernel_size=2),\n",
        "                                     nn.BatchNorm1d(input_dim), nn.ReLU()) # here to reduce noice\n",
        "        self.convnet2 = nn.Sequential(nn.Conv1d(in_channels=input_dim, out_channels=2*input_dim, kernel_size=4,\n",
        "                                               padding=2), nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "                                     nn.BatchNorm1d(2*input_dim), nn.ReLU())  # start extracting features and reduce size\n",
        "                                                                              # ro reduce complexity for lstm\n",
        "        self.convnet3 = nn.Sequential(nn.Conv1d(in_channels=2*input_dim, out_channels=4*input_dim, kernel_size=4,\n",
        "                                               padding=2), nn.MaxPool1d(kernel_size=2),\n",
        "                                     nn.BatchNorm1d(4*input_dim), nn.ReLU())\n",
        "        self.convnet4 = nn.Sequential(nn.Conv1d(in_channels=4*input_dim, out_channels=8*input_dim, kernel_size=4,\n",
        "                                               padding=2), nn.BatchNorm1d(8*input_dim), nn.ReLU())\n",
        "        self.convnet5 = nn.Conv1d(in_channels=8*input_dim, out_channels=16*input_dim, kernel_size=4, padding=2)\n",
        "        self.lstm = nn.LSTMCell(16*input_dim, hidden_dim)\n",
        "        self.hiddentoff = nn.Linear(hidden_dim, int(np.sqrt(hidden_dim)))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fftolabel = nn.Linear(int(np.sqrt(hidden_dim)), label_size)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.device = device\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "        for name, param in self.hiddentoff.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "        for name, param in self.fftolabel.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0001)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
        "        x = self.convnet1(x)\n",
        "        x = self.convnet2(x)\n",
        "        x = self.convnet3(x)\n",
        "        x = self.convnet4(x)\n",
        "        x = self.convnet5(x)\n",
        "        x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
        "        x = self.dropout(x)\n",
        "        hs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "        cs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "\n",
        "        for i in range(x.size()[1]):\n",
        "            hs, cs = self.lstm(x[:, i], (hs, cs))\n",
        "            # hs = self.dropout(hs)\n",
        "            # cs = self.dropout(cs)\n",
        "\n",
        "        hs = self.dropout(hs)\n",
        "        hs = self.relu(hs)\n",
        "        hs = self.hiddentoff(hs)\n",
        "\n",
        "        # return self.sigmoid(self.hidden2label(hs.reshape(x.shape[0], -1)))\n",
        "        return self.sigmoid(self.fftolabel(hs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtJ6uXdMZ_dG"
      },
      "source": [
        "To summarize, those models performed much better on the train set (reaching 90% accuracy for V0.3 and 98% accuracy for V0.1) however had a very hard time generalizing their learning (only ~55% accuracy for both) on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnMHilyLaWSP"
      },
      "source": [
        "## CNN_LSTM with Attention\n",
        "\n",
        "This is an even more complex version of the CNN_LSTM model that **hasn't been ran or tested yet**. This is here only to give inspiration of what could be done to improve the model's performance even further once more data is available. This model is a CNN_LSTM that uses a part of Transformer models called Attention coupled with a Encoder/Decoder structure, which allows the model to focus and extract more information on important parts of the sequence. This one uses the V0.3 structure of the CNN_LSTM.\n",
        "\n",
        "The upsides are that it is even more powerful than the CNN_LSTM, however, since it has at least twice the amount of parameters, it will need even more data to train properly so it might have difficulties generalizing.\n",
        "\n",
        "To learn more about Attention, how it works and how it can be used, I recommend reading https://arxiv.org/abs/1706.03762 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5q64kqdbI3S"
      },
      "source": [
        "\n",
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # A two layer fully-connected network\n",
        "        # hidden_size*2 --> hidden_size, ReLU, hidden_size --> 1\n",
        "        self.attention_network = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the additive attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state. (batch_size x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x 1 x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The attention_weights must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "        batch_size = keys.size(0)\n",
        "        expanded_queries = queries.view(batch_size, -1, self.hidden_size).expand_as(keys)\n",
        "        concat_inputs = torch.cat([expanded_queries, keys], dim=2)\n",
        "        unnormalized_attention = self.attention_network(concat_inputs)\n",
        "        attention_weights = self.softmax(unnormalized_attention)\n",
        "        context = torch.bmm(attention_weights.transpose(2, 1), values)\n",
        "        return context, attention_weights\n",
        "\n",
        "\n",
        "class CNN_LSTM_Attention_Classifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Version V0.0\n",
        "    CNN+LSTM classifier using ConvNet -> LSTMCell + Attention -> FFNetwork structure\n",
        "    \"\"\"\n",
        "    class ConvNet(nn.Module):\n",
        "        def __init__(self, input_dim, dropout_rate):\n",
        "            super().__init__()\n",
        "            self.convnet1 = nn.Sequential(nn.Conv1d(in_channels=input_dim, out_channels=input_dim, kernel_size=7,\n",
        "                                                    padding=2), nn.MaxPool1d(kernel_size=4),\n",
        "                                          nn.BatchNorm1d(input_dim), nn.ReLU())  # here to reduce noice\n",
        "            self.convnet2 = nn.Sequential(nn.Conv1d(in_channels=input_dim, out_channels=2 * input_dim, kernel_size=5,\n",
        "                                                    padding=2), nn.MaxPool1d(kernel_size=4),\n",
        "                                          nn.BatchNorm1d(2 * input_dim),\n",
        "                                          nn.ReLU())  # start extracting features and reduce size\n",
        "            # to reduce complexity for lstm\n",
        "            self.convnet3 = nn.Sequential(\n",
        "                nn.Conv1d(in_channels=2 * input_dim, out_channels=4 * input_dim, kernel_size=3,\n",
        "                          padding=2), nn.MaxPool1d(kernel_size=2),\n",
        "                nn.BatchNorm1d(4 * input_dim), nn.ReLU())\n",
        "            # removed to reduce model complexity to try and limit overfitting\n",
        "            # self.convnet4 = nn.Sequential(nn.Conv1d(in_channels=4*input_dim, out_channels=8*input_dim, kernel_size=4,\n",
        "            #                                        padding=2), nn.BatchNorm1d(8*input_dim), nn.ReLU())\n",
        "            # self.convnet5 = nn.Conv1d(in_channels=8*input_dim, out_channels=16*input_dim, kernel_size=4, padding=2)\n",
        "            # self.lstm = nn.LSTMCell(16*input_dim, hidden_dim)\n",
        "            self.convnet5 = nn.Conv1d(in_channels=4 * input_dim, out_channels=4 * input_dim, kernel_size=4, padding=2)\n",
        "            self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
        "            x = self.convnet1(x)\n",
        "            x = self.convnet2(x)\n",
        "            x = self.convnet3(x)\n",
        "            # x = self.convnet4(x)\n",
        "            x = self.convnet5(x)\n",
        "            x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
        "            x = self.dropout(x)\n",
        "            return x\n",
        "\n",
        "    class CNN_LSTM_Encoder(nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dim, dropout_rate):\n",
        "            super().__init__()\n",
        "            self.convnet = self.ConvNet(input_dim, dropout_rate)\n",
        "            self.lstm = nn.LSTMCell(4*input_dim, hidden_dim)\n",
        "\n",
        "        def forward(self, x):\n",
        "            hs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "            cs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "\n",
        "            x = self.convnet(x)\n",
        "            annotations = []\n",
        "\n",
        "            for i in range(x.size()[1]):\n",
        "                hs, cs = self.lstm(x[:, i], (hs, cs))\n",
        "                annotations.append(hs)\n",
        "\n",
        "            annotations = torch.stack(annotations, dim=1)\n",
        "            return annotations, hs, cs\n",
        "\n",
        "        def initialize_weights(self):\n",
        "            for name, param in self.lstm.named_parameters():\n",
        "                if 'bias' in name:\n",
        "                    nn.init.constant_(param, 0.0001)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_normal_(param)\n",
        "\n",
        "    class CNN_LSTM_Decoder(nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dim, label_size, dropout_rate=0.1):\n",
        "            super().__init__()\n",
        "            self.convnet = self.ConvNet(input_dim, dropout_rate)\n",
        "            self.lstm = nn.LSTMCell(8 * input_dim, hidden_dim)\n",
        "            self.hiddentoff = nn.Linear(hidden_dim, int(np.sqrt(hidden_dim)))\n",
        "            self.relu = nn.ReLU()\n",
        "            self.fftolabel = nn.Linear(int(np.sqrt(hidden_dim)), label_size)\n",
        "            self.hidden_dim = hidden_dim\n",
        "            self.sigmoid = nn.Sigmoid()\n",
        "            self.dropout = nn.Dropout(dropout_rate)\n",
        "            self.attention = AdditiveAttention(hidden_size=hidden_dim)\n",
        "            self.initialize_weights()\n",
        "\n",
        "        def initialize_weights(self):\n",
        "            for name, param in self.lstm.named_parameters():\n",
        "                if 'bias' in name:\n",
        "                    nn.init.constant_(param, 0.0001)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_normal_(param)\n",
        "            for name, param in self.hiddentoff.named_parameters():\n",
        "                if 'bias' in name:\n",
        "                    nn.init.constant_(param, 0.0001)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_normal_(param)\n",
        "            for name, param in self.fftolabel.named_parameters():\n",
        "                if 'bias' in name:\n",
        "                    nn.init.constant_(param, 0.0001)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_normal_(param)\n",
        "\n",
        "        def forward(self, x, annotations, h_init, c_init):\n",
        "            x = self.convnet(x)\n",
        "            # hs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "            # cs = torch.zeros(x.size(0), self.hidden_dim).to(self.device)\n",
        "            hs = h_init\n",
        "            cs = c_init\n",
        "\n",
        "            for i in range(x.size()[1]):\n",
        "                context, attention_weights = self.attention(hs, annotations, annotations)\n",
        "                cur_input = x[:, i]\n",
        "                cur_input = torch.cat([cur_input, context.squeeze(1)], dim=1)\n",
        "                hs, cs = self.lstm(cur_input, (hs, cs))\n",
        "\n",
        "            hs = self.dropout(hs)\n",
        "            hs = self.hiddentoff(hs)\n",
        "            hs = self.relu(hs)\n",
        "            # return self.sigmoid(self.hidden2label(hs.reshape(x.shape[0], -1)))\n",
        "            return self.sigmoid(self.fftolabel(hs))\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, label_size, device=torch.device(\"cuda\"), dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = self.CNN_LSTM_Encoder(input_dim, hidden_dim, dropout_rate)\n",
        "        self.decoder = self.CNN_LSTM_Decoder(input_dim, hidden_dim, label_size,dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_annotations, encoder_hidden, encoder_cell = self.encoder(x)\n",
        "        decoder_outputs = self.decoder(x, encoder_annotations, encoder_hidden, encoder_cell)\n",
        "        return decoder_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R_jikuvbZGO"
      },
      "source": [
        "## Transformer\n",
        "\n",
        "Finally, the last model that could be worth testing once more data is available is a transformer itself. I don't have an implementation of it ready, however, as time passes and since it's a fairly new and popular model, it will be easy to find existing implementations online and adapt them to the particular task at hand. Highly recommend looking into as soon as possible. \n",
        "\n",
        "Upsides are that it allows for better parallelization than the LSTM structure and therefore would train much faster on a larger dataset, however it requires more memory to train. It also suffers from being a complex model to train and requiring a large amount of data to train properly.\n",
        "\n",
        "A good first step to learn more about transformers would be to check out https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQkCNBfRdcMa"
      },
      "source": [
        "# Train, Run and Test Code\n",
        "\n",
        "We now come to the code that pieces it all together. The train code is the code that will implement what we like to call the \"training loop\" to train the model.\n",
        "This training loop consists of fetching the batches of data we want to train our model on, feeding them to our model and using the predicted output with the ground truth labels to compute a loss. Then we backpropagate the gradient of the loss w.r.t the different parts of the model through the model using whatever loss/optimizer prefered.\n",
        "\n",
        "The run code is the code that pieces all the different elements together: initializes the model, loads the datasets, sets up the iteration procedure for the train loop etc...\n",
        "\n",
        "And finally the test code is what allows us to validate our model and observe how it performs on new data it hasn't seen before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxSGmTaov_NG"
      },
      "source": [
        "## Train Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34I9YSvUUE4K"
      },
      "source": [
        "For the train code, there are multiple ways to implement it. I will cover the two that I know off. We have:\n",
        "\n",
        "*   Coding it manually\n",
        "*   Torch Ignite\n",
        "\n",
        "The loop can be and usually is coded manually. This is good to do when you want to add custom behavior to your training that can deviate from the norm. However, if the training process is straightforward and is virtually the same as the basic training function that I will describe below, then it can be good to instead use torch ignite instead.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMyss_kzdgyN"
      },
      "source": [
        "\n",
        "def train_nn(batch_loader: DataLoader, model: torch.nn.Module, criterion, optimizer, testing: bool,\n",
        "             device: torch.device):\n",
        "  '''A standard training loop'''\n",
        "    if testing:\n",
        "        model.eval()\n",
        "        #bar = Bar('Testing', max=len(batch_loader))\n",
        "    else:\n",
        "        model.train()\n",
        "        #bar = Bar('Training', max=len(batch_loader))\n",
        "\n",
        "    # Progress bar stuff\n",
        "    #batch_time = AverageMeter()\n",
        "    #data_time = AverageMeter()\n",
        "    losses = AverageMeter()    # can be found in the utils/misc.py code file\n",
        "    #end = time.time()\n",
        "    for batch_idx, (inputs, target) in enumerate(batch_loader):\n",
        "        # Measure data loading time\n",
        "        #data_time.update(time.time() - end)\n",
        "        inputs = inputs.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(inputs)\n",
        "\n",
        "        total_loss = criterion(output, target)\n",
        "\n",
        "        # Record loss\n",
        "        losses.update(total_loss.item(), inputs.size(0))\n",
        "\n",
        "        if not testing:\n",
        "            # Compute gradient and do SGD step\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Measure elapsed time\n",
        "        #batch_time.update(time.time() - end)\n",
        "        #end = time.time()\n",
        "\n",
        "        # plot progress\n",
        "        #bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | Loss: {loss:.4f} | Gen Loss: {gen_loss: .4f} | Action Loss: {action_loss: .4f}'.format(\n",
        "            #batch=batch_idx + 1,\n",
        "            #size=len(batch_loader),\n",
        "            #data=data_time.avg,\n",
        "            #bt=batch_time.avg,\n",
        "            #total=bar.elapsed_td,\n",
        "            #loss=losses.avg,\n",
        "            #gen_loss=float(0),\n",
        "            #action_loss=float(total_loss)\n",
        "        #)\n",
        "        #bar.next()\n",
        "\n",
        "    #bar.finish()\n",
        "    return losses.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsfFIMT6VyB5"
      },
      "source": [
        "### Torch Ignite\n",
        "\n",
        "To learn the details of how torch ignite works, I recommend you check out https://pytorch.org/ignite/index.html for more details. \n",
        "\n",
        "What ignite does is that it helps simplify and streamline the training process of networks and allows for easy re-use of code across the board.\n",
        "It also has a nice integration with tensorboard (https://pytorch.org/docs/stable/tensorboard.html) which allows for an easier result logging process.\n",
        "\n",
        "All the torch ignite code is setup in the run file (file we actually run) so I will first detail how to run a regular network without torch ignite and tensorboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDkspGCeWnsO"
      },
      "source": [
        "## Run Code/Test code\n",
        "So now that we have the train code, we can talk about the actual run file itself and how it is setup.\n",
        "First you obviously want to import all the code that we discussed above so it can be used to train your model.\n",
        "I will then detail the steps and code in the code box below\n",
        "The test code is contained within the run code and the train code, hence it doesn't require an extra section. However, when you're not using ignite, it does require the creation of a \"test function\", i.e a function that will compute the particular metric you want to look into. We have a basic accuracy computation function defined below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deBGAs-vcOjn"
      },
      "source": [
        "def compute_accuracy(predictions, targets):\n",
        "    \"\"\"Computes an accuracy based on the given predictions and targets\"\"\"\n",
        "    assert len(predictions) == len(targets)\n",
        "\n",
        "    accuracy_array = []\n",
        "\n",
        "    if len(np.shape(targets)) == 1:\n",
        "\n",
        "        for (idx, pred), (_, t) in zip(enumerate(predictions), enumerate(targets)):\n",
        "            accuracy_array.append(1) if pred == t else accuracy_array.append(0)\n",
        "\n",
        "    else:\n",
        "\n",
        "        for (idx, pred), (_, t) in zip(enumerate(predictions), enumerate(targets)):\n",
        "            accuracy_array.append(1) if np.argmax(pred) == np.argmax(t) else accuracy_array.append(0)\n",
        "\n",
        "    accuracy = float(sum(accuracy_array))/float(len(accuracy_array))\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEjhjUanWnIt"
      },
      "source": [
        "def run():\n",
        "    # we do this to make sure gpu training is available, it is highly recommended to train the models on gpu \n",
        "    # assert torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    \n",
        "    # Dataloading parameters\n",
        "    pin_memory = (device.type == \"cuda\")\n",
        "    num_workers = 8   # this represents the number of cpu threads you want to assign to the dataloading, the more the better\n",
        "    batch_size = 2048   # the size of the batches that are fed to the model\n",
        "\n",
        "    # Model input parameters\n",
        "    input_size = 8    # the number of channels in the input data\n",
        "    hidden_size = 50    # how many neurons we want your hidden layers to have, more means a more complex model\n",
        "    dropout_rate = 0.3    # the probability that any given input will be replaced by a 0 at the dropout layers of the model (should usually be between 0.1 and 0.5 depending on the complexity of the model)\n",
        "\n",
        "    # Training parameters\n",
        "    epochs = 1000     # the number of training loops\n",
        "    learning_rate = 0.001   # the learning rate, usually initialized between 0.01 and 0.0001\n",
        "\n",
        "    # we initialize the model\n",
        "    nn = CNN_LSTM_Classifier(input_size, hidden_size, label_size=2, device=device, dropout_rate=dropout_rate)\n",
        "    nn = nn.to(device) # put it on the gpu if a gpu is available\n",
        "\n",
        "    # we get the dataloaders \n",
        "    train_loader, test_loader = torch_all_channels_raw_data_loader(batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "    # we initialize the optimizer that will train our model, here we use Adam\n",
        "    # but there is usually a prefered optimizer for each model, this can be easily found on Google.\n",
        "    # By default, Adam is a good all-round optimizer that can work for most models\n",
        "    optimizer = optim.Adam(nn.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "    # the loss function, will depend on the data you are working with,\n",
        "    # the number of classes and their type as well as personal preference (again here, Google is your friend)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    # Now we arrive to the training/testing code\n",
        "\n",
        "    # We'll define an extra variable, that is there to set how often you want to validate your model during training\n",
        "    validation_rate = 5   # we'll set it to every 5 epochs for now\\\n",
        "    validation_counter = 1\n",
        "    # We iterate over the decided number of epochs\n",
        "    for i in range(epochs):\n",
        "        # we first train the model\n",
        "        train_loss = train_nn(train_loader, nn, criterion, optimizer, testing=False, device=device)\n",
        "        print(\"Epoch {} | Training Loss {}\".format(i, train_loss))\n",
        "\n",
        "        # we check if we need to validate the model\n",
        "        if validation_counter == validation_rate:\n",
        "            # we don't calculate gradients since we are testing the model\n",
        "            with torch.no_grad():\n",
        "                test_loss = train_nn(test_loader, nn, criterion, optimizer, testing=True, device=device)\n",
        "                print(\"Epoch {} | Test Loss {}\".format(i, test_loss))\n",
        "            validation_counter = 1\n",
        "        else:\n",
        "            validation_counter += 1\n",
        "\n",
        "    # Now that we are done training the model, we can actually test it using whichever testing function you decided to define\n",
        "    accuracy = AverageMeter()\n",
        "    for batch_idx, (inputs, target) in enumerate(test_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(inputs)\n",
        "\n",
        "        acc = compute_accuracy(output.numpy(), target.numpy())\n",
        "        accuracy.update(acc, inputs.size(0))\n",
        "\n",
        "  print('final test accuracy: {}'.format(accuracy.avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMsjJvugAT3L"
      },
      "source": [
        "### Torch Ignite\n",
        "\n",
        "Now I'll present the same run/train/test code using pytorch ignite with tensorboard.\n",
        "First for conveniance, I'm going to share a function that allows for easy creation of tensorboard log directories. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zkxYX-6BnjV"
      },
      "source": [
        "def get_tensorboard_log_dir():\n",
        "    if not path.exists('../results/files/tb_logs'):\n",
        "        return path.join(\"../results/files/tb_logs\")\n",
        "    i = 1\n",
        "    while path.exists('../results/files/tb_logs_{}'.format(i)):\n",
        "        i += 1\n",
        "    return path.join(\"../results/files/tb_logs_{}\".format(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7bXpr0PBpAx"
      },
      "source": [
        "We'll now setup the event handler for ignite. It catches whatever trigger we want to feed it and then performs custom actions on them. For example, the first trigger below is triggered whenever an epoch is completed and the log_training_loss function is then called. This function prints the loss to standard out and logs it to the current tensorboard summary writer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V24RGNSWCIRH"
      },
      "source": [
        "def setup_event_handler(trainer, evaluator, train_loader, test_loader):\n",
        "    log_interval = 10\n",
        "\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_training_loss(trainer):\n",
        "        print(\"Epoch[{}] Loss: {:.5f}\".format(trainer.state.epoch, trainer.state.output))\n",
        "        writer.add_scalar(\"training_iteration_loss\", trainer.state.output, trainer.state.epoch)\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED(every=log_interval))\n",
        "    def log_training_results(trainer):\n",
        "        evaluator.run(train_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        print(\"Training Results - Epoch: {}  Accuracy: {:.5f} Loss: {:.5f}\"\n",
        "                     .format(trainer.state.epoch, metrics[\"accuracy\"], metrics[\"nll\"]))\n",
        "        writer.add_scalar(\"training_loss\", metrics[\"nll\"], trainer.state.epoch)\n",
        "        writer.add_scalar(\"training_accuracy\", metrics[\"accuracy\"], trainer.state.epoch)\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED(every=log_interval))\n",
        "    def log_testing_results(trainer):\n",
        "        evaluator.run(test_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        print(\"Validation Results - Epoch: {}  Accuracy: {:.5f} Loss: {:.5f}\"\n",
        "                     .format(trainer.state.epoch, metrics[\"accuracy\"], metrics[\"nll\"]))\n",
        "        writer.add_scalar(\"testing_loss\", metrics[\"nll\"], trainer.state.epoch)\n",
        "        writer.add_scalar(\"testing_accuracy\", metrics[\"accuracy\"], trainer.state.epoch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fDV-lIrCKcQ"
      },
      "source": [
        "We could see above the presence of both a trainer and evaluator object. Those objects are the base of the ignite system. They take in your model, optimizer and criterion (as well as a metric function for the evaluator) and then take care of all the training/evaluation code.\n",
        "\n",
        "Below, we have the rest of the run code, as you can see, the hyperparameter initialization remains pretty much the same, however the second part is much shorter and we don't need to write out own train function anymore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CQ5MELmCwm7"
      },
      "source": [
        "def run():\n",
        "    # we do this to make sure gpu training is available, it is highly recommended to train the models on gpu \n",
        "    # assert torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    \n",
        "    # Dataloading parameters\n",
        "    pin_memory = (device.type == \"cuda\")\n",
        "    num_workers = 8   # this represents the number of cpu threads you want to assign to the dataloading, the more the better\n",
        "    batch_size = 2048   # the size of the batches that are fed to the model\n",
        "\n",
        "    # Model input parameters\n",
        "    input_size = 8    # the number of channels in the input data\n",
        "    hidden_size = 50    # how many neurons we want your hidden layers to have, more means a more complex model\n",
        "    dropout_rate = 0.3    # the probability that any given input will be replaced by a 0 at the dropout layers of the model (should usually be between 0.1 and 0.5 depending on the complexity of the model)\n",
        "\n",
        "    # Training parameters\n",
        "    epochs = 1000     # the number of training loops\n",
        "    learning_rate = 0.001   # the learning rate, usually initialized between 0.01 and 0.0001\n",
        "\n",
        "    # we initialize the model\n",
        "    nn = CNN_LSTM_Classifier(input_size, hidden_size, label_size=2, device=device, dropout_rate=dropout_rate)\n",
        "    nn = nn.to(device) # put it on the gpu if a gpu is available\n",
        "\n",
        "    # we get the dataloaders \n",
        "    train_loader, test_loader = torch_all_channels_raw_data_loader(batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "    # we initialize the optimizer that will train our model, here we use Adam\n",
        "    # but there is usually a prefered optimizer for each model, this can be easily found on Google.\n",
        "    # By default, Adam is a good all-round optimizer that can work for most models\n",
        "    optimizer = optim.Adam(nn.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "    # the loss function, will depend on the data you are working with,\n",
        "    # the number of classes and their type as well as personal preference (again here, Google is your friend)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    # we now initialize the trainer\n",
        "    trainer = create_supervised_trainer(nn, optimizer, criterion, device=device)\n",
        "\n",
        "    # I have to define an extra function here that will take in the output of my model and format it in a proper format\n",
        "    # for us to feed it into the Accuracy metric function\n",
        "    def ot_func(output):\n",
        "        y_pred, y = output\n",
        "        y_pred = torch.nn.functional.one_hot(torch.max(y_pred, 1)[1], num_classes=2).to(torch.float)\n",
        "        return (y_pred, y)\n",
        "\n",
        "    # here we define the dictionnary of all the metrics we want our evaluator to look at,\n",
        "    # for now I just used the Accuracy function that can be found in ignite.metrics as well as the loss\n",
        "    # many more metrics can be found in the ignite.metrics package\n",
        "    val_metrics = {\n",
        "        \"accuracy\": Accuracy(output_transform=partial(ot_func)),\n",
        "        \"nll\": Loss(criterion)\n",
        "    }\n",
        "\n",
        "    # now that we have all the pre-requisits set up, we can initialize the evaluator\n",
        "    evaluator = create_supervised_evaluator(nn, metrics=val_metrics, device=device)\n",
        "\n",
        "    # we now call the setup for the triggers defined previously\n",
        "    setup_event_handler(trainer, evaluator, train_loader, test_loader)\n",
        "\n",
        "    # and finally we can just train the model for the specified number of epochs by just calling the run function\n",
        "    trainer.run(train_loader, max_epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yekNeIOOD-_P"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "To conclude this notebook, I first to note that if you are confused about any part of this code, then feel free to get in contact with me (you can find my most recent contact info on https://www.fenaux.ca/).\n",
        "Secondly, one part I didn't really cover was the imports, as I didn't want to make the notebook too convoluted. However, if you want to see how it's done, you can check out the original code files on the github repository."
      ]
    }
  ]
}